{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa+69IVZDe2s7otQ0CLKqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viper-s03/daily/blob/main/day11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxrXHJtc3xdA",
        "outputId": "19365b72-7e66-4838-9d1f-3bc465464d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: \n",
            "\n",
            "    Hello there!\n",
            "This is an example paragraph.\n",
            "It will be tokenized into words and sentences.\n",
            "Let's see how well the NLTK tokenizer works.\n",
            "Hopefully, it will separate the text correctly.\n",
            "\n",
            "Words: \n",
            "['Hello', 'there', '!', 'This', 'is', 'an', 'example', 'paragraph', '.', 'It', 'will', 'be', 'tokenized', 'into', 'words', 'and', 'sentences', '.', 'Let', \"'s\", 'see', 'how', 'well', 'the', 'NLTK', 'tokenizer', 'works', '.', 'Hopefully', ',', 'it', 'will', 'separate', 'the', 'text', 'correctly', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Sample paragraph\n",
        "paragraph = \"\"\"\n",
        "    Hello there! This is an example paragraph. It will be tokenized into words and sentences.\n",
        "    Let's see how well the NLTK tokenizer works. Hopefully, it will separate the text correctly.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the paragraph into sentences\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# Tokenize the paragraph into words\n",
        "words = word_tokenize(paragraph)\n",
        "\n",
        "# Print the results\n",
        "print(\"Sentences: \")\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "\n",
        "print(\"\\nWords: \")\n",
        "print(words)\n"
      ]
    }
  ]
}